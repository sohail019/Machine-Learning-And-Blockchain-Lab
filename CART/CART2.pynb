import numpy as np

# Sample dataset (features)
X = np.array([[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]])
# Corresponding target labels (0 for class A, 1 for class B)
y = np.array([0, 1, 0, 1, 1, 0])

class DecisionTree:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth

    def fit(self, X, y, depth=0):
        num_samples, num_features = X.shape
        unique_classes, num_unique_classes = np.unique(y, return_counts=True)

# Check if only one class remains or the tree depth limit is reached
        if num_unique_classes == 1 or (self.max_depth and depth == self.max_depth):
            return unique_classes[0]

        # If there are no more features to split or all samples belong to one class
        if num_features == 0 or num_unique_classes == 1:
            return unique_classes[np.argmax(num_unique_classes)]

        # Find the best split
        best_split = self.find_best_split(X, y)
        if best_split is None:
            return unique_classes[np.argmax(num_unique_classes)]

 # Recursive splitting
        feature_idx, threshold = best_split
        left_mask = X[:, feature_idx] <= threshold
        right_mask = ~left_mask
        left_subtree = self.fit(X[left_mask], y[left_mask], depth + 1)
        right_subtree = self.fit(X[right_mask], y[right_mask], depth + 1)

        return (feature_idx, threshold, left_subtree, right_subtree)
 def find_best_split(self, X, y):
        num_samples, num_features = X.shape
        if num_samples <= 1:
            return None

        parent_gini = self.gini(y)

        best_gini = 1.0
        best_split = None

        for feature_idx in range(num_features):
            thresholds = np.unique(X[:, feature_idx])
            for threshold in thresholds:
                left_mask = X[:, feature_idx] <= threshold
                right_mask = ~left_mask

                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:
                    continue

                left_gini = self.gini(y[left_mask])
                right_gini = self.gini(y[right_mask])

                weighted_gini = (np.sum(left_mask) / num_samples) * left_gini + (np.sum(right_mask) / num_samples) * right_gini

                if weighted_gini < best_gini:
                    best_gini = weighted_gini
                    best_split = (feature_idx, threshold)

        return best_split

 def gini(self, y):
        _, counts = np.unique(y, return_counts=True)
        probs = counts / len(y)
        return 1 - np.sum(probs ** 2

def predict(self, X):
        return np.array([self._predict(x) for x in X])

    def _predict(self, x):
        if isinstance(self.tree, np.ndarray):
            return self.tree

        feature_idx, threshold, left_subtree, right_subtree = self.tree
        if x[feature_idx] <= threshold:
            return self._predict(left_subtree)
        else:
            return self._predict(right_subtree)


# Create a CART classifier and fit it to the dataset
cart_classifier = DecisionTree(max_depth=3)
cart_classifier.tree = cart_classifier.fit(X, y)

# Test the classifier on new data
new_data = np.array([[3, 4], [6, 5]])
predictions = cart_classifier.predict(new_data)

for i, prediction in enumerate(predictions):
    print(f"Data {new_data[i]} is predicted as class {prediction}")

